[
    {
        "instance_id": "a73335d8352c93f9ac1956c190bd8cbe",
        "question": "What are all the labels for the slices of the pie chart?",
        "answer_pred": "['1', '2', '3', '4', '5']",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2: Distribution of votes in the final version of the corpus. The numbers 1 to 5 are the different scores the annotators could assign to the humorous tweets.\n\nQuestion: What are all the labels for the slices of the pie chart?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "c551d1f0a7b2c5a68d02abc3be1eed41",
        "question": "Is the percentage of tweets considered 'not humor' greater than the percentage of tweets with a score of 2?",
        "answer_pred": "Yes",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2: Distribution of votes in the final version of the corpus. The numbers 1 to 5 are the different scores the annotators could assign to the humorous tweets.\n\nQuestion: Is the percentage of tweets considered 'not humor' greater than the percentage of tweets with a score of 2?\nReturn either 'Yes' or 'No'. Do not add anything else - not even punctuation marks."
            }
        ]
    },
    {
        "instance_id": "3cf8604eff230ce0530582a2203a5d53",
        "question": "Which score was given most often by annotators?",
        "answer_pred": "1",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2: Distribution of votes in the final version of the corpus. The numbers 1 to 5 are the different scores the annotators could assign to the humorous tweets.\n\nQuestion: Which score was given most often by annotators?\nBased on the reasoning above, match it to one or more of the provided answer options: {'A': None, 'B': None, 'C': None, 'D': 'All of the above'}. Return only the corresponding letter(s) of the correct answer(s). Do not explain your choice, do not rephrase the answer, and do not repeat the option text. Only output the letter(s) corresponding to the correct choice. If multiple letters are correct, separate them by commas without spaces (for example: B,C). If all options are correct, return A,B,C,D. Do not add anything else."
            }
        ]
    },
    {
        "instance_id": "e404565c67a4037a36f41c11aed3a894",
        "question": "What is the mean score assigned by the annotators to the humorous tweets, and how is it presented in the figure?",
        "answer_pred": "3.00",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2: Distribution of votes in the final version of the corpus. The numbers 1 to 5 are the different scores the annotators could assign to the humorous tweets.\n\nQuestion: What is the mean score assigned by the annotators to the humorous tweets, and how is it presented in the figure?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "54439f3c8296012d879d62e502452270",
        "question": "How many CoNLL test sentences have a depth of 0?",
        "answer_pred": "1",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Allocation of the 977 CoNLL test sentences.\n\nQuestion: How many CoNLL test sentences have a depth of 0?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "aae7ab943a464200d8fe5dba0faafc36",
        "question": "Are more than half of the CoNLL test sentences allocated to sentence depth 0?",
        "answer_pred": "Yes",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Allocation of the 977 CoNLL test sentences.\n\nQuestion: Are more than half of the CoNLL test sentences allocated to sentence depth 0?\nReturn either 'Yes' or 'No'. Do not add anything else - not even punctuation marks."
            }
        ]
    },
    {
        "instance_id": "fcd2e7c677e66864c61ef529d52a2805",
        "question": "Which of the following sentence depths are represented in the figure?",
        "answer_pred": "D",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Allocation of the 977 CoNLL test sentences.\n\nQuestion: Which of the following sentence depths are represented in the figure?\nBased on the reasoning above, match it to one or more of the provided answer options: {'A': None, 'B': None, 'C': None, 'D': 'All of the above'}. Return only the corresponding letter(s) of the correct answer(s). Do not explain your choice, do not rephrase the answer, and do not repeat the option text. Only output the letter(s) corresponding to the correct choice. If multiple letters are correct, separate them by commas without spaces (for example: B,C). If all options are correct, return A,B,C,D. Do not add anything else."
            }
        ]
    },
    {
        "instance_id": "912a4cc2587f4fb68c4ac798b4f88589",
        "question": "What is the average sentence depth of the 977 CoNLL test sentences, and how is it presented in the figure?",
        "answer_pred": "11.1",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Allocation of the 977 CoNLL test sentences.\n\nQuestion: What is the average sentence depth of the 977 CoNLL test sentences, and how is it presented in the figure?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "f372e3f6ad05397f97b030f9c80b0330",
        "question": "What is the macro-label of the x-axis?",
        "answer_pred": "F1",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 4: Varying the amount of training data for the discourse parser, we can see how parsing F1 performance affects accuracy on the Yelp review task.\n\nQuestion: What is the macro-label of the x-axis?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "1ade3768a000c139b5ad6bcb997b9e8b",
        "question": "Does increasing the amount of training data for the discourse parser improve accuracy on the Yelp review task?",
        "answer_pred": "Yes",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 4: Varying the amount of training data for the discourse parser, we can see how parsing F1 performance affects accuracy on the Yelp review task.\n\nQuestion: Does increasing the amount of training data for the discourse parser improve accuracy on the Yelp review task?\nReturn either 'Yes' or 'No'. Do not add anything else - not even punctuation marks."
            }
        ]
    },
    {
        "instance_id": "2fbc13ae7d6aef21a2a7f891e08b203f",
        "question": "What is the range of the accuracy values?",
        "answer_pred": "D",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 4: Varying the amount of training data for the discourse parser, we can see how parsing F1 performance affects accuracy on the Yelp review task.\n\nQuestion: What is the range of the accuracy values?\nBased on the reasoning above, match it to one or more of the provided answer options: {'A': None, 'B': None, 'C': None, 'D': '70.8 to 90'}. Return only the corresponding letter(s) of the correct answer(s). Do not explain your choice, do not rephrase the answer, and do not repeat the option text. Only output the letter(s) corresponding to the correct choice. If multiple letters are correct, separate them by commas without spaces (for example: B,C). If all options are correct, return A,B,C,D. Do not add anything else."
            }
        ]
    },
    {
        "instance_id": "67ea316f6ae0265d00a2e7f2b1381951",
        "question": "What is the amount of training data used to achieve the accuracy of 71.2 on the Yelp review task, and how does it affect the accuracy results?",
        "answer_pred": "1000",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 4: Varying the amount of training data for the discourse parser, we can see how parsing F1 performance affects accuracy on the Yelp review task.\n\nQuestion: What is the amount of training data used to achieve the accuracy of 71.2 on the Yelp review task, and how does it affect the accuracy results?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "99f7e8687723b3f3a8c6d4a2867f935c",
        "question": "What is the macro-label of the x-axis?",
        "answer_pred": "Workload",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Cohen\u2019s \u03ba agreement for stance annotation on 98 comments. As a trade-off between reducing costs (i.e., discarding fewer instances) and increasing reliability, we chose 5 annotators and a threshold of 0.95 for this task, which resulted in \u03ba = 0.58 (moderate to substantial agreement).\n\nQuestion: What is the macro-label of the x-axis?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "80337bc61b1547c88d1539a565501dc6",
        "question": "Is the Cohen's \u03ba agreement higher for 5 annotators with a threshold of 0.95 than for 5 annotators with a threshold of 0.85?",
        "answer_pred": "Yes",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Cohen\u2019s \u03ba agreement for stance annotation on 98 comments. As a trade-off between reducing costs (i.e., discarding fewer instances) and increasing reliability, we chose 5 annotators and a threshold of 0.95 for this task, which resulted in \u03ba = 0.58 (moderate to substantial agreement).\n\nQuestion: Is the Cohen's \u03ba agreement higher for 5 annotators with a threshold of 0.95 than for 5 annotators with a threshold of 0.85?\nReturn either 'Yes' or 'No'. Do not add anything else - not even punctuation marks."
            }
        ]
    },
    {
        "instance_id": "73cc71b26ac8b203a8c9a4ae8ef0a883",
        "question": "What is maximum Cohen's Kappa value in y-axis?",
        "answer_pred": "B",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Cohen\u2019s \u03ba agreement for stance annotation on 98 comments. As a trade-off between reducing costs (i.e., discarding fewer instances) and increasing reliability, we chose 5 annotators and a threshold of 0.95 for this task, which resulted in \u03ba = 0.58 (moderate to substantial agreement).\n\nQuestion: What is maximum Cohen's Kappa value in y-axis?\nBased on the reasoning above, match it to one or more of the provided answer options: {'A': None, 'B': None, 'C': None, 'D': '0.3'}. Return only the corresponding letter(s) of the correct answer(s). Do not explain your choice, do not rephrase the answer, and do not repeat the option text. Only output the letter(s) corresponding to the correct choice. If multiple letters are correct, separate them by commas without spaces (for example: B,C). If all options are correct, return A,B,C,D. Do not add anything else."
            }
        ]
    },
    {
        "instance_id": "f21489a1f78b2067fadcfafe69ae6517",
        "question": "How was Cohen's  Kappa calculated and how does it affect the results? ",
        "answer_pred": "Cohen's \u03ba was calculated using the formula for Cohen's \u03ba, which is the proportion of agreement between two raters divided by the product of the standard deviations of the two raters' ratings. The result of Cohen's \u03ba for stance annotation on 98 comments was 0.58, which indicates moderate to substantial agreement. This means that there is a moderate to substantial level of agreement between the two raters in their stance annotations. The result of Cohen's \u03ba affects the results by providing a measure of the level of agreement between the two raters, which can be used to evaluate the reliability of the annotations. A higher value of Cohen's \u03ba indicates a higher level of agreement and a more reliable annotation process.",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 3: Cohen\u2019s \u03ba agreement for stance annotation on 98 comments. As a trade-off between reducing costs (i.e., discarding fewer instances) and increasing reliability, we chose 5 annotators and a threshold of 0.95 for this task, which resulted in \u03ba = 0.58 (moderate to substantial agreement).\n\nQuestion: How was Cohen's  Kappa calculated and how does it affect the results? \nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "724c348e5cd3acde6c28a7f725d072db",
        "question": "What is the range of the average emotional response?",
        "answer_pred": "-0.1",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFig. 7. Average number of discussions (threads) initiated by websites (squares) and users (circles) that have received a specific average emotional response. All threads with a threshold Ncomments \u2265 8.\n\nQuestion: What is the range of the average emotional response?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "55763b7826096e95a31d9c30a704d74f",
        "question": "Do websites and users start at the same number of threads for a given average emotional response?",
        "answer_pred": "No",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFig. 7. Average number of discussions (threads) initiated by websites (squares) and users (circles) that have received a specific average emotional response. All threads with a threshold Ncomments \u2265 8.\n\nQuestion: Do websites and users start at the same number of threads for a given average emotional response?\nReturn either 'Yes' or 'No'. Do not add anything else - not even punctuation marks."
            }
        ]
    },
    {
        "instance_id": "1e2178e771e2417e37bc85aa4284235a",
        "question": "What is the range of the average number of threads?",
        "answer_pred": "D",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFig. 7. Average number of discussions (threads) initiated by websites (squares) and users (circles) that have received a specific average emotional response. All threads with a threshold Ncomments \u2265 8.\n\nQuestion: What is the range of the average number of threads?\nBased on the reasoning above, match it to one or more of the provided answer options: {'A': None, 'B': None, 'C': None, 'D': '0 to 10'}. Return only the corresponding letter(s) of the correct answer(s). Do not explain your choice, do not rephrase the answer, and do not repeat the option text. Only output the letter(s) corresponding to the correct choice. If multiple letters are correct, separate them by commas without spaces (for example: B,C). If all options are correct, return A,B,C,D. Do not add anything else."
            }
        ]
    },
    {
        "instance_id": "36c419cde3ca2e26a013feb32a70cc61",
        "question": "What is the average emotional response that corresponds to the peak of the blue line representing websites, and how is it presented in the figure?",
        "answer_pred": "4.0",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFig. 7. Average number of discussions (threads) initiated by websites (squares) and users (circles) that have received a specific average emotional response. All threads with a threshold Ncomments \u2265 8.\n\nQuestion: What is the average emotional response that corresponds to the peak of the blue line representing websites, and how is it presented in the figure?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "63ed8de0518c18b5b1efb5ad7e9b9d23",
        "question": "What is the classification result measured by F-measure at the threshold 0.7, in the second plot?",
        "answer_pred": "0.82",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2. Impact of the threshold on the classification results\n\nQuestion: What is the classification result measured by F-measure at the threshold 0.7, in the second plot?\nGive the exact correct answer, with no extra explanation."
            }
        ]
    },
    {
        "instance_id": "2a0769147b2417fdadaa382353f00777",
        "question": "Does the F-measure consistently decrease as the threshold increases?",
        "answer_pred": "Yes",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2. Impact of the threshold on the classification results\n\nQuestion: Does the F-measure consistently decrease as the threshold increases?\nReturn either 'Yes' or 'No'. Do not add anything else - not even punctuation marks."
            }
        ]
    },
    {
        "instance_id": "55b03b0f9408194955db99a4b565c13c",
        "question": "Which of the following classification performance metrics decreases as the threshold increases?",
        "answer_pred": "D",
        "reasoning": [
            {
                "role": "user",
                "content": "<|image_1|>\nFigure 2. Impact of the threshold on the classification results\n\nQuestion: Which of the following classification performance metrics decreases as the threshold increases?\nBased on the reasoning above, match it to one or more of the provided answer options: {'A': None, 'B': None, 'C': None, 'D': 'All of the above'}. Return only the corresponding letter(s) of the correct answer(s). Do not explain your choice, do not rephrase the answer, and do not repeat the option text. Only output the letter(s) corresponding to the correct choice. If multiple letters are correct, separate them by commas without spaces (for example: B,C). If all options are correct, return A,B,C,D. Do not add anything else."
            }
        ]
    }
]